{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mosek\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from torch import optim\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import cvxpy as cp\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "seed = 2023\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "erm_ = False\n",
    "\n",
    "data_train = pd.read_csv('adult.data', header=None)\n",
    "data_test = pd.read_csv('adult.test', header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample data frame for solver stability, comment out for erm performance\n",
    "if not erm_:\n",
    "    data_train = data_train.sample(frac=0.2, random_state=1)\n",
    "    data_train = data_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6512, 102) (6512,) (16281, 102) (16281,)\n"
     ]
    }
   ],
   "source": [
    "n_test = data_test.shape[0]\n",
    "merge = pd.concat([data_train, data_test], axis=0)\n",
    "y = merge[merge.columns[-1]].map(lambda x: '>50K' in x)\n",
    "merge = merge.drop(merge.columns[-1], axis=1)\n",
    "X = []\n",
    "\n",
    "for col in merge.columns:\n",
    "  if merge[col].dtype == 'object':\n",
    "    X.append(pd.get_dummies(merge[col], prefix=col))\n",
    "  # else:\n",
    "  #   X.append(merge[col])\n",
    "merge_df = pd.concat(X, axis=1)\n",
    "X = pd.concat(X, axis=1).to_numpy()\n",
    "X_train, y_train = X[:-n_test, :], y[:-n_test]\n",
    "X_test, y_test = X[-n_test:, :], y[-n_test:]\n",
    "# convert to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6512, 102), 0.2281941031941032, 0.23622627602727106)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.sum() / y_train.shape[0], y_test.sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 6438)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di = None\n",
    "for i, j in enumerate(merge_df.columns):\n",
    "    if 'Doctorate' in j:\n",
    "        di = i\n",
    "        \n",
    "doc_idx = X_train[:, di] == 1 \n",
    "non_doc_idx = X_train[:, di] == 0\n",
    "\n",
    "doc_idx.sum(), non_doc_idx.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpsolver(prob, verbose=False):\n",
    "#   print('=== LP Solver ===')\n",
    "  solvers = [cp.MOSEK, cp.ECOS_BB]\n",
    "  for s in solvers:\n",
    "    # print('==> Invoking {}...'.format(s))\n",
    "    try:\n",
    "      result = prob.solve(solver=s, verbose=verbose)\n",
    "      return result\n",
    "    except cp.error.SolverError as e:\n",
    "      print('==> Solver Error')\n",
    "\n",
    "#   print('==> Invoking MOSEK simplex method...')\n",
    "  try:\n",
    "    result = prob.solve(solver=cp.MOSEK,\n",
    "                      mosek_params={'MSK_IPAR_OPTIMIZER': mosek.optimizertype.free_simplex},\n",
    "                      bfs=True, verbose=verbose)\n",
    "    return result\n",
    "  except cp.error.SolverError as e:\n",
    "    print('==> Solver Error')\n",
    "\n",
    "  raise cp.error.SolverError('All solvers failed.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    super(MyDataset, self).__init__()\n",
    "    self.X = X.astype('float32')\n",
    "    self.y = y.astype('long')\n",
    "    self.attr = X\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    return self.X[item], self.y[item]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "dataset_train = MyDataset(X_train, y_train)\n",
    "dataset_test_train = MyDataset(X_train, y_train)\n",
    "dataset_valid = MyDataset(X_test, y_test)\n",
    "dataset_test = MyDataset(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(102, 2, bias=True))\n",
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erm(model: Module, loader: DataLoader, optimizer: optim.Optimizer, criterion, device: str, iters=0):\n",
    "  \"\"\"Empirical Risk Minimization (ERM)\"\"\"\n",
    "\n",
    "  model.train()\n",
    "  iteri = 0\n",
    "  for _, (inputs, targets) in enumerate(loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    iteri += 1\n",
    "    if iteri == iters:\n",
    "      break\n",
    "\n",
    "def test(model: Module, loader: DataLoader, criterion, device: str):\n",
    "  \"\"\"Test the avg and group acc of the model\"\"\"\n",
    "\n",
    "  model.eval()\n",
    "  total_correct = 0\n",
    "  total_loss = 0\n",
    "  total_num = 0\n",
    "  l_rec = []\n",
    "  c_rec = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for _, (inputs, targets) in enumerate(loader):\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      labels = targets\n",
    "      outputs = model(inputs)\n",
    "      predictions = torch.argmax(outputs, dim=1)\n",
    "      c = (predictions == labels)\n",
    "      c_rec.append(c.detach().cpu().numpy())\n",
    "      correct = c.sum().item()\n",
    "      l = criterion(outputs, labels).view(-1)\n",
    "      l_rec.append(l.detach().cpu().numpy())\n",
    "      loss = l.sum().item()\n",
    "      total_correct += correct\n",
    "      total_loss += loss\n",
    "      total_num += len(inputs)\n",
    "  l_vec = np.concatenate(l_rec)\n",
    "  c_vec = np.concatenate(c_rec)\n",
    "  return total_correct / total_num, total_loss / total_num, c_vec, l_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if erm_:\n",
    "    batch_size = 128\n",
    "    doc_idx_test = X_test[:, di] == 1\n",
    "    non_doc_idx_test = X_test[:, di] == 0\n",
    "\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "    trainloader = DataLoader(dataset_train, batch_size=128, shuffle=True)\n",
    "    testloader = DataLoader(dataset_test, batch_size=128, shuffle=False)\n",
    "    doc_testloader = DataLoader(dataset_test, batch_size=batch_size, sampler=SubsetRandomSampler(np.where(doc_idx_test)[0]), num_workers=0, pin_memory=False)\n",
    "    non_doc_testloader = DataLoader(dataset_test, batch_size=batch_size, sampler=SubsetRandomSampler(np.where(non_doc_idx_test)[0]), num_workers=0, pin_memory=False) \n",
    "\n",
    "    erm(model, trainloader, optimizer, loss, 'cpu', iters=1000)\n",
    "    acc, _, c_vec, _ = test(model, testloader, loss, 'cpu')\n",
    "    print(\"Test Loss: \", 1 - test(model, testloader, loss, 'cpu')[0])\n",
    "    print(\"Doc Test Loss: \", 1 - test(model, doc_testloader, loss, 'cpu')[0])\n",
    "    print(\"Non-Doc Test Loss: \", 1 - test(model, non_doc_testloader, loss, 'cpu')[0])\n",
    "\n",
    "    num_classes = len(np.unique(y_test))\n",
    "    dct = {}\n",
    "    for i in range(num_classes):\n",
    "        idx = np.where(y_test == i)[0]\n",
    "        dct[i] = 1 - c_vec[idx].mean()\n",
    "    print(\"Class Loss: \", dct)\n",
    "    print(\"Worst Class Loss: \", max(dct.values()))\n",
    "\n",
    "    assert False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAI GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raigame(P, l_all, eta, constraints_w=['group_doro', 'chi2'], alpha=0.2, group_idx=[non_doc_idx]):\n",
    "    num_epochs, n = l_all.shape\n",
    "    w = cp.Variable(n)\n",
    "    \n",
    "    objective = cp.Maximize(P @ (l_all @ w) + eta * cp.sum(cp.entr(w)))\n",
    "    constraints = []\n",
    "    constraints.append(cp.sum(w) == 1)\n",
    "    constraints.append(1e-10 <= w)\n",
    "    # add constraints\n",
    "    nc = len(constraints_w)\n",
    "    if 'cvar' in constraints_w:\n",
    "      m = alpha * n\n",
    "      constraints.append(w <= 1 / m)\n",
    "      nc -= 1\n",
    "    if 'chi2' in constraints_w:\n",
    "      m = alpha * n\n",
    "      constraints.append(cp.sum_squares(w) <= 1 / m)\n",
    "      nc -= 1\n",
    "    if 'group_doro' in constraints_w:\n",
    "      for idx in group_idx:\n",
    "        constraints.append(cp.sum_squares(w[idx]) * idx.sum() <= 0.80)\n",
    "      nc -= 1\n",
    "    if nc > 0:\n",
    "      print('Constraint {} not implemented'.format(constraints_w))\n",
    "      raise NotImplementedError\n",
    "    #################\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    result = lpsolver(prob, verbose=False)\n",
    "    \n",
    "    w_star = w.value\n",
    "    w_star[w_star < 0] = 0\n",
    "    w_star /= w_star.sum()\n",
    "    return w_star, result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005069391183956586 0.04451636141358459\n",
      "t=0, loss=0.17613636363636365\n",
      "t = 1, gamevalue = 0.37560221476052613, max_w_star = 0.00015356265356265356\n",
      "t=1, loss=0.18181818181818182\n",
      "t = 2, gamevalue = 0.3535192324457604, max_w_star = 0.005075837585677506\n",
      "t=2, loss=0.17536855036855037\n",
      "t = 3, gamevalue = 0.3486805830701639, max_w_star = 0.00553651135725408\n",
      "t=3, loss=0.17367936117936117\n",
      "t = 4, gamevalue = 0.3479659828464426, max_w_star = 0.005652895424075107\n",
      "t=4, loss=0.17045454545454544\n",
      "t = 5, gamevalue = 0.3469469346268142, max_w_star = 0.0056470912164671245\n",
      "t=5, loss=0.17137592137592136\n",
      "t = 6, gamevalue = 0.3469985694557651, max_w_star = 0.00566535963389098\n",
      "t=6, loss=0.17168304668304668\n",
      "t = 7, gamevalue = 0.34700916441520663, max_w_star = 0.005697744600997216\n",
      "t=7, loss=0.17291154791154792\n",
      "t = 8, gamevalue = 0.34704582246038773, max_w_star = 0.005766462305578386\n",
      "t=8, loss=0.17352579852579852\n",
      "t = 9, gamevalue = 0.3470980220230002, max_w_star = 0.005907241364253679\n",
      "t=9, loss=0.17122235872235872\n",
      "t = 10, gamevalue = 0.3469861892505549, max_w_star = 0.006188932669350762\n",
      "t=10, loss=0.17398648648648649\n",
      "t = 11, gamevalue = 0.3469898109420303, max_w_star = 0.006175454099324509\n",
      "t=11, loss=0.17444717444717445\n",
      "t = 12, gamevalue = 0.3470187576209018, max_w_star = 0.0066769865738747275\n",
      "t=12, loss=0.1765970515970516\n",
      "t = 13, gamevalue = 0.34704179465439794, max_w_star = 0.007391000738689482\n",
      "t=13, loss=0.17598280098280097\n",
      "t = 14, gamevalue = 0.3470884398475803, max_w_star = 0.004615253421803562\n",
      "t=14, loss=0.17367936117936117\n",
      "t = 15, gamevalue = 0.3471447671212765, max_w_star = 0.0026235739064575433\n"
     ]
    }
   ],
   "source": [
    "init_state_dict = deepcopy(model.state_dict())\n",
    "T = 15\n",
    "iters_per_epoch = 500\n",
    "batch_size = 128\n",
    "w_all = np.zeros((0, len(dataset_train)))\n",
    "l_all = np.zeros((0, len(dataset_train)))\n",
    "P = np.zeros((1, 0))\n",
    "n = len(dataset_train)\n",
    "eta =  0.05 * (np.log(T) / (2 * T * np.log(n))) ** 0.5\n",
    "print(eta, eta * np.log(n))\n",
    "\n",
    "w_all = np.concatenate([w_all, np.ones((1, n)) / n])\n",
    "\n",
    "test_trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False) # for testing\n",
    "prev_gamevalue = np.inf\n",
    "best_gamevalue, best_P = np.inf, None\n",
    "models = []\n",
    "for t in range(T):\n",
    "    #set-up model\n",
    "    model.load_state_dict(init_state_dict)\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "    #set-up loader\n",
    "    w_t = w_all[-1, :]\n",
    "    sampler = WeightedRandomSampler(w_t, iters_per_epoch * batch_size, replacement=True)\n",
    "    trainloader = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler, num_workers=0, pin_memory=False)\n",
    "    \n",
    "    #get ht (or lt)    \n",
    "    erm(model, trainloader, optimizer, loss, 'cpu', iters_per_epoch)\n",
    "    models.append(deepcopy(model.state_dict()))\n",
    "    _, _, c_t, ce_t = test(model, test_trainloader, loss, 'cpu')\n",
    "    l_t = 1 - c_t # get 0-1 loss\n",
    "    l_all = np.concatenate([l_all, l_t.reshape(1, -1)], axis=0)\n",
    "    print('t={}, loss={}'.format(t, l_t.mean()))\n",
    "    # do line search for a    \n",
    "    base_a = 1 / (t + 1)\n",
    "    best_value = np.inf\n",
    "    best_a = 1 / (t + 1)\n",
    "    for m_a in [0.1, 1, 1.5]:\n",
    "        a = base_a * m_a\n",
    "        if a >= 1:\n",
    "            continue\n",
    "        P_temp = np.concatenate([(1 - a) * P, a * np.ones((1, 1))], axis=1)\n",
    "        P_temp = P_temp / P_temp.sum()\n",
    "        _, value = raigame(P_temp, l_all, 0)\n",
    "        if not value < np.inf:\n",
    "            continue   \n",
    "        if value < best_value:\n",
    "            best_value = value\n",
    "            best_a = a\n",
    "    P = np.concatenate([(1 - best_a) * P, best_a * np.ones((1, 1))], axis=1)\n",
    "    P = P / P.sum()\n",
    "    \n",
    "    # get new game value\n",
    "    _, gamevalue = raigame(P, l_all, 0)\n",
    "    print('t = {}, gamevalue = {}, max_w_star = {}'.format(t + 1, gamevalue, w_t.max()))\n",
    "    \n",
    "    # update best gamevalue\n",
    "    if gamevalue < best_gamevalue:\n",
    "        best_gamevalue = gamevalue\n",
    "        best_P = P\n",
    "        \n",
    "    # update eta if gamevalue increases\n",
    "    if prev_gamevalue < gamevalue:\n",
    "        eta = eta * 2\n",
    "    prev_gamevalue = gamevalue\n",
    "    \n",
    "    #get wt\n",
    "    w_t, L_P = raigame(P, l_all, eta)\n",
    "    w_all = np.concatenate([w_all, w_t.reshape(1, -1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_P = np.concatenate([best_P, np.zeros((1, T - best_P.shape[1]))], axis=1)\n",
    "P = best_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.175, 0.175, 0.175, 0.175, 0.3  , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   , 0.   , 0.   , 0.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_erm = 0.37560221476052635, game_opt = 0.3469469346268142, game_unif = 0.3516071116972247\n"
     ]
    }
   ],
   "source": [
    "P_erm = np.zeros((1, T))\n",
    "P_erm[:, 0] = 1\n",
    "\n",
    "P_unif = np.ones((1, T)) / T\n",
    "\n",
    "_, game_erm = raigame(P_erm, l_all, 0)\n",
    "_, game_opt = raigame(P, l_all, 0)\n",
    "_, game_unif = raigame(P_unif, l_all, 0)\n",
    "\n",
    "print('game_erm = {}, game_opt = {}, game_unif = {}'.format(game_erm, game_opt, game_unif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.1, opt_cvar = 1.000, erm_cvar = 1.000, unif_cvar = 1.000\n",
      "alpha = 0.2, opt_cvar = 0.831, erm_cvar = 0.881, unif_cvar = 0.844\n",
      "alpha = 0.3, opt_cvar = 0.583, erm_cvar = 0.587, unif_cvar = 0.581\n",
      "alpha = 0.4, opt_cvar = 0.437, erm_cvar = 0.440, unif_cvar = 0.436\n",
      "alpha = 0.5, opt_cvar = 0.350, erm_cvar = 0.352, unif_cvar = 0.348\n",
      "alpha = 0.6, opt_cvar = 0.291, erm_cvar = 0.294, unif_cvar = 0.290\n",
      "alpha = 0.7, opt_cvar = 0.250, erm_cvar = 0.252, unif_cvar = 0.249\n",
      "alpha = 0.8, opt_cvar = 0.219, erm_cvar = 0.220, unif_cvar = 0.218\n",
      "alpha = 0.9, opt_cvar = 0.194, erm_cvar = 0.196, unif_cvar = 0.194\n",
      "alpha = 1, opt_cvar = 0.175, erm_cvar = 0.176, unif_cvar = 0.174\n"
     ]
    }
   ],
   "source": [
    "# Analyze CVaR Loss\n",
    "def get_cvar_loss(P, l, alpha):\n",
    "    exp_loss = (P @ l).reshape(-1)\n",
    "    exp_loss = np.sort(exp_loss)[::-1]\n",
    "    n = exp_loss.shape[0]\n",
    "    return format(exp_loss[:int(alpha * n)].mean(), '.3f')\n",
    "\n",
    "for alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "    print('alpha = {}, opt_cvar = {}, erm_cvar = {}, unif_cvar = {}'.format(alpha, get_cvar_loss(P, l_all, alpha), get_cvar_loss(P_erm, l_all, alpha), get_cvar_loss(P_unif, l_all, alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5026,)\n",
      "1 (1486,)\n",
      "Class Loss:  {0: 0.07661659371269398, 1: 0.507150067294751}\n",
      "Worst Class Loss:  0.507150067294751\n",
      "0 (5026,)\n",
      "1 (1486,)\n",
      "Class Loss:  {0: 0.05113410266613609, 1: 0.5989232839838493}\n",
      "Worst Class Loss:  0.5989232839838493\n"
     ]
    }
   ],
   "source": [
    "# Analyze worst-class loss\n",
    "def get_worst_class_loss(P, l, dataset):\n",
    "    assert len(dataset) == l.shape[1]\n",
    "    exp_loss = (P @ l).reshape(-1)\n",
    "    num_classes = len(np.unique(dataset.y))\n",
    "    dct = {}\n",
    "    for i in range(num_classes):\n",
    "        idx = np.where(dataset.y == i)[0]\n",
    "        print(i, idx.shape)\n",
    "        dct[i] = exp_loss[idx].mean()\n",
    "    print(\"Class Loss: \", dct)\n",
    "    print(\"Worst Class Loss: \", max(dct.values()))\n",
    "    return \n",
    "\n",
    "get_worst_class_loss(P, l_all, dataset_train)\n",
    "get_worst_class_loss(P_erm, l_all, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17228671457527178"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader = DataLoader(dataset_test, batch_size=128, shuffle=False)\n",
    "acc = test(model, testloader, loss, 'cpu')[0]\n",
    "1 - acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.3038674 , 0.25966851, 0.24309392, 0.25414365, 0.26519337,\n",
       "        0.25414365, 0.25966851, 0.25414365, 0.24861878, 0.25414365,\n",
       "        0.25414365, 0.28176796, 0.28729282, 0.28176796, 0.28176796]),\n",
       " array([0.26519337]),\n",
       " array([0.1736646 , 0.17732919, 0.1773913 , 0.17062112, 0.16925466,\n",
       "        0.17      , 0.16819876, 0.17      , 0.16857143, 0.17161491,\n",
       "        0.17378882, 0.17465839, 0.1778882 , 0.17770186, 0.1710559 ]),\n",
       " array([0.17310248]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx_test = X_test[:, di] == 1\n",
    "non_doc_idx_test = X_test[:, di] == 0\n",
    "\n",
    "def get_acc(P, models, loader):\n",
    "    acc = []\n",
    "    for mod in models:\n",
    "        model.load_state_dict(mod)\n",
    "        acc.append(test(model, loader, loss, 'cpu')[0])\n",
    "    return np.array(acc), P @ acc\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "doc_testloader = DataLoader(dataset_test, batch_size=batch_size, sampler=SubsetRandomSampler(np.where(doc_idx_test)[0]), num_workers=0, pin_memory=False)\n",
    "non_doc_testloader = DataLoader(dataset_test, batch_size=batch_size, sampler=SubsetRandomSampler(np.where(non_doc_idx_test)[0]), num_workers=0, pin_memory=False) \n",
    "\n",
    "acc_doc, acc_doc_avg = get_acc(P, models, doc_testloader)\n",
    "acc_non_doc, acc_non_doc_avg = get_acc(P, models, non_doc_testloader)\n",
    "1 - acc_doc, 1 - acc_doc_avg, 1 - acc_non_doc, 1 - acc_non_doc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_doc, acc_doc_avg = get_acc(P_unif, models, doc_testloader)\n",
    "# acc_non_doc, acc_non_doc_avg = get_acc(P_unif, models, non_doc_testloader)\n",
    "# acc_doc, acc_doc_avg, acc_non_doc, acc_non_doc_avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
