{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mosek\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from torch import optim\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import cvxpy as cp\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "seed = 2023\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "erm_ = False\n",
    "\n",
    "data_train = pd.read_csv('fashion-mnist_train.csv', header=None, skiprows=1)\n",
    "data_test = pd.read_csv('fashion-mnist_test.csv', header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tshirt, pullover and shirt data\n",
    "data_train = data_train[data_train[0].isin([0,2,6])]\n",
    "data_test = data_test[data_test[0].isin([0,2,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample data frame for solver stability, comment out for erm performance\n",
    "if True:\n",
    "    data_train = data_train.sample(frac=0.8, random_state=42)\n",
    "    data_train = data_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = data_test.shape[0]\n",
    "merge = pd.concat([data_train, data_test], axis=0)\n",
    "dct = {0: 0, 2: 1, 6: 2}\n",
    "y = merge[merge.columns[0]].map(lambda x: dct[x]).to_numpy()\n",
    "merge = merge.drop(merge.columns[0], axis=1)\n",
    "\n",
    "merge_df = merge\n",
    "X = merge.to_numpy()\n",
    "X_train, y_train = X[:-n_test, :], y[:-n_test]\n",
    "X_test, y_test = X[-n_test:, :], y[-n_test:]\n",
    "# convert to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, (y_train == 0).sum(), (y_train == 1).sum(), (y_train == 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tshirt_idx_train = np.where(y_train == 0)[0]\n",
    "pull_idx_train = np.where(y_train == 1)[0]\n",
    "shirt_idx_train = np.where(y_train == 2)[0]\n",
    "\n",
    "tshirt_idx_test = np.where(y_test == 0)[0]\n",
    "pull_idx_test = np.where(y_test == 1)[0]\n",
    "shirt_idx_test = np.where(y_test == 2)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpsolver(prob, verbose=False):\n",
    "#   print('=== LP Solver ===')\n",
    "  solvers = [cp.MOSEK, cp.ECOS_BB]\n",
    "  for s in solvers:\n",
    "    # print('==> Invoking {}...'.format(s))\n",
    "    try:\n",
    "      result = prob.solve(solver=s, verbose=verbose)\n",
    "      return result\n",
    "    except cp.error.SolverError as e:\n",
    "      print('==> Solver Error')\n",
    "\n",
    "#   print('==> Invoking MOSEK simplex method...')\n",
    "  try:\n",
    "    result = prob.solve(solver=cp.MOSEK,\n",
    "                      mosek_params={'MSK_IPAR_OPTIMIZER': mosek.optimizertype.free_simplex},\n",
    "                      bfs=True, verbose=verbose)\n",
    "    return result\n",
    "  except cp.error.SolverError as e:\n",
    "    print('==> Solver Error')\n",
    "\n",
    "  raise cp.error.SolverError('All solvers failed.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    super(MyDataset, self).__init__()\n",
    "    self.X = X.astype('float32')\n",
    "    self.y = y.astype('long')\n",
    "    self.attr = X\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    return self.X[item], self.y[item]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "dataset_train = MyDataset(X_train, y_train)\n",
    "dataset_test_train = MyDataset(X_train, y_train)\n",
    "dataset_valid = MyDataset(X_test, y_test)\n",
    "dataset_test = MyDataset(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 3, bias=True))\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "testloader = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erm(model: Module, loader: DataLoader, optimizer: optim.Optimizer, criterion, device: str, iters=0):\n",
    "  \"\"\"Empirical Risk Minimization (ERM)\"\"\"\n",
    "\n",
    "  model.train()\n",
    "  iteri = 0\n",
    "  avg_loss = 0\n",
    "  for _, (inputs, targets) in enumerate(loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets).mean()\n",
    "    avg_loss += loss.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    iteri += 1\n",
    "    if iteri == iters:\n",
    "      break\n",
    "\n",
    "def test(model: Module, loader: DataLoader, criterion, device: str):\n",
    "  \"\"\"Test the avg and group acc of the model\"\"\"\n",
    "\n",
    "  model.eval()\n",
    "  total_correct = 0\n",
    "  total_loss = 0\n",
    "  total_num = 0\n",
    "  l_rec = []\n",
    "  c_rec = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for _, (inputs, targets) in enumerate(loader):\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      labels = targets\n",
    "      outputs = model(inputs)\n",
    "      predictions = torch.argmax(outputs, dim=1)\n",
    "      c = (predictions == labels)\n",
    "      c_rec.append(c.detach().cpu().numpy())\n",
    "      correct = c.sum().item()\n",
    "      l = criterion(outputs, labels).view(-1)\n",
    "      l_rec.append(l.detach().cpu().numpy())\n",
    "      loss = l.sum().item()\n",
    "      total_correct += correct\n",
    "      total_loss += loss\n",
    "      total_num += len(inputs)\n",
    "  l_vec = np.concatenate(l_rec)\n",
    "  c_vec = np.concatenate(c_rec)\n",
    "  return total_correct / total_num, total_loss / total_num, c_vec, l_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if erm_:\n",
    "    batch_size = 32\n",
    "    iters = 1000\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "    trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    for i in range(5):\n",
    "        erm(model, trainloader, optimizer, loss, 'cpu', iters=iters)\n",
    "        acc, _, c_vec, _ = test(model, trainloader, loss, 'cpu')\n",
    "        print(\"Train Acc: \", acc, end=', ')\n",
    "    acc, _, c_vec, _ = test(model, testloader, loss, 'cpu')\n",
    "    print(\"Test Loss: \", 1 - acc)\n",
    "    print(\"shirt Loss: \", 1 - c_vec[shirt_idx_test].mean())\n",
    "    print(\"pull Loss: \", 1 - c_vec[pull_idx_test].mean())\n",
    "    print(\"tshirt Loss: \", 1 - c_vec[tshirt_idx_test].mean())\n",
    "\n",
    "    # assert False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAI GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raigame(P, l_all, eta, constraints_w=['group_doro', 'chi2'], alpha=0.55, group_idx=[pull_idx_train, tshirt_idx_train, shirt_idx_train]):\n",
    "    num_epochs, n = l_all.shape\n",
    "    w = cp.Variable(n)\n",
    "    \n",
    "    objective = cp.Maximize(P @ (l_all @ w) + eta * cp.sum(cp.entr(w)))\n",
    "    constraints = []\n",
    "    constraints.append(cp.sum(w) == 1)\n",
    "    constraints.append(1e-10 <= w)\n",
    "    # add constraints\n",
    "    nc = len(constraints_w)\n",
    "    if 'cvar' in constraints_w:\n",
    "      m = alpha * n\n",
    "      constraints.append(w <= 1 / m)\n",
    "      nc -= 1\n",
    "    if 'chi2' in constraints_w:\n",
    "      m = alpha * n\n",
    "      constraints.append(cp.sum_squares(w) <= 1 / m)\n",
    "      nc -= 1\n",
    "    if 'group_doro' in constraints_w:\n",
    "      # calculate entropy between groups\n",
    "      constraints.append(cp.entr(cp.vstack([cp.sum(w[idx]) for idx in group_idx])) >= 0.1)\n",
    "      nc -= 1\n",
    "    if nc > 0:\n",
    "      print('Constraint {} not implemented'.format(constraints_w))\n",
    "      raise NotImplementedError\n",
    "    #################\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    result = lpsolver(prob, verbose=False)\n",
    "    \n",
    "    w_star = w.value\n",
    "    w_star[w_star < 0] = 0\n",
    "    w_star /= w_star.sum()\n",
    "    return w_star, result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state_dict = deepcopy(model.state_dict())\n",
    "T = 4\n",
    "iters_per_epoch = 2000\n",
    "batch_size = 512\n",
    "w_all = np.zeros((0, len(dataset_train)))\n",
    "l_all = np.zeros((0, len(dataset_train)))\n",
    "P = np.zeros((1, 0))\n",
    "n = len(dataset_train)\n",
    "eta =  10 * (np.log(T) / (2 * T * np.log(n))) ** 0.5\n",
    "print(eta, eta * np.log(n))\n",
    "\n",
    "w_all = np.concatenate([w_all, np.ones((1, n)) / n])\n",
    "\n",
    "test_trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False) # for testing\n",
    "prev_gamevalue = np.inf\n",
    "best_gamevalue, best_P = np.inf, None\n",
    "models = []\n",
    "for t in range(T):\n",
    "    #set-up model\n",
    "    model.load_state_dict(init_state_dict)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-1)\n",
    "\n",
    "    #set-up loader\n",
    "    w_t = w_all[-1, :]\n",
    "    sampler = WeightedRandomSampler(w_t, iters_per_epoch * batch_size, replacement=True)\n",
    "    trainloader = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler, num_workers=0, pin_memory=False)\n",
    "    \n",
    "    #get ht (or lt)    \n",
    "    erm(model, trainloader, optimizer, loss, 'cpu', iters_per_epoch)\n",
    "    models.append(deepcopy(model.state_dict()))\n",
    "    _, _, c_t, ce_t = test(model, test_trainloader, loss, 'cpu')\n",
    "    l_t = 1 - c_t # get 0-1 loss\n",
    "    l_all = np.concatenate([l_all, l_t.reshape(1, -1)], axis=0)\n",
    "    print('t={}, loss={}'.format(t, l_t.mean()))\n",
    "    # do line search for a    \n",
    "    base_a = 1 / (t + 1)\n",
    "    best_value = np.inf\n",
    "    best_a = 1 / (t + 1)\n",
    "    for m_a in [0.1, 1, 1.5]:\n",
    "        a = base_a * m_a\n",
    "        if a >= 1:\n",
    "            continue\n",
    "        P_temp = np.concatenate([(1 - a) * P, a * np.ones((1, 1))], axis=1)\n",
    "        P_temp = P_temp / P_temp.sum()\n",
    "        _, value = raigame(P_temp, l_all, 0)\n",
    "        if not value < np.inf:\n",
    "            continue   \n",
    "        if value < best_value:\n",
    "            best_value = value\n",
    "            best_a = a\n",
    "    P = np.concatenate([(1 - best_a) * P, best_a * np.ones((1, 1))], axis=1)\n",
    "    P = P / P.sum()\n",
    "    \n",
    "    # get new game value\n",
    "    _, gamevalue = raigame(P, l_all, 0)\n",
    "    print('t = {}, gamevalue = {}, max_w_star = {}'.format(t + 1, gamevalue, w_t.max()))\n",
    "    \n",
    "    # update best gamevalue\n",
    "    if gamevalue < best_gamevalue:\n",
    "        best_gamevalue = gamevalue\n",
    "        best_P = P\n",
    "        \n",
    "    # update eta if gamevalue increases\n",
    "    if prev_gamevalue < gamevalue:\n",
    "        eta = eta * 2\n",
    "    prev_gamevalue = gamevalue\n",
    "    \n",
    "    #get wt\n",
    "    w_t, L_P = raigame(P, l_all, eta)\n",
    "    w_all = np.concatenate([w_all, w_t.reshape(1, -1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_P = np.concatenate([best_P, np.zeros((1, T - best_P.shape[1]))], axis=1)\n",
    "P = best_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_erm = np.zeros((1, T))\n",
    "P_erm[:, 0] = 1\n",
    "\n",
    "P_unif = np.ones((1, T)) / T\n",
    "\n",
    "_, game_erm = raigame(P_erm, l_all, 0)\n",
    "_, game_opt = raigame(P, l_all, 0)\n",
    "_, game_unif = raigame(P_unif, l_all, 0)\n",
    "\n",
    "print('game_erm = {}, game_opt = {}, game_unif = {}'.format(game_erm, game_opt, game_unif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CVaR Loss\n",
    "def get_cvar_loss(P, l, alpha):\n",
    "    exp_loss = (P @ l).reshape(-1)\n",
    "    exp_loss = np.sort(exp_loss)[::-1]\n",
    "    n = exp_loss.shape[0]\n",
    "    return format(exp_loss[:int(alpha * n)].mean(), '.3f')\n",
    "\n",
    "for alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "    print('alpha = {}, opt_cvar = {}, erm_cvar = {}, unif_cvar = {}'.format(alpha, get_cvar_loss(P, l_all, alpha), get_cvar_loss(P_erm, l_all, alpha), get_cvar_loss(P_unif, l_all, alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze worst-class loss\n",
    "def get_worst_class_loss(P, l, dataset):\n",
    "    assert len(dataset) == l.shape[1]\n",
    "    exp_loss = (P @ l).reshape(-1)\n",
    "    num_classes = len(np.unique(dataset.y))\n",
    "    dct = {}\n",
    "    for i in range(num_classes):\n",
    "        idx = np.where(dataset.y == i)[0]\n",
    "        print(i, idx.shape)\n",
    "        dct[i] = exp_loss[idx].mean()\n",
    "    print(\"Class Loss: \", dct)\n",
    "    print(\"Worst Class Loss: \", max(dct.values()))\n",
    "    return \n",
    "\n",
    "get_worst_class_loss(P, l_all, dataset_train)\n",
    "get_worst_class_loss(P_erm, l_all, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P[:, 5:] = 0\n",
    "P = P / P.sum()\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(P, models, loader):\n",
    "    acc = []\n",
    "    for mod in models:\n",
    "        model.load_state_dict(mod)\n",
    "        acc.append(test(model, loader, loss, 'cpu')[0])\n",
    "    return np.array(acc), P @ acc\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "tshirt_testloader = DataLoader(dataset_test, batch_size=batch_size, sampler=SubsetRandomSampler(np.where(dataset_test.y == 0)[0]), num_workers=0, pin_memory=False)\n",
    "pull_testloader = DataLoader(dataset_test, batch_size=batch_size, sampler=SubsetRandomSampler(np.where(dataset_test.y == 1)[0]), num_workers=0, pin_memory=False)\n",
    "shirt_testloader = DataLoader(dataset_test, batch_size=batch_size, sampler=SubsetRandomSampler(np.where(dataset_test.y == 2)[0]), num_workers=0, pin_memory=False)\n",
    "\n",
    "acc_tshirt, acc_tshirt_avg = get_acc(P, models, tshirt_testloader)\n",
    "acc_pull, acc_pull_avg = get_acc(P, models, pull_testloader)\n",
    "acc_shirt, acc_shirt_avg = get_acc(P, models, shirt_testloader)\n",
    "overall_acc, overall_acc_avg = get_acc(P, models, testloader)\n",
    "\n",
    "1 - acc_tshirt_avg, 1 - acc_pull_avg, 1 - acc_shirt_avg, 1 - overall_acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tshirt, acc_tshirt_avg = get_acc(P_erm, models, tshirt_testloader)\n",
    "acc_pull, acc_pull_avg = get_acc(P_erm, models, pull_testloader)\n",
    "acc_shirt, acc_shirt_avg = get_acc(P_erm, models, shirt_testloader)\n",
    "overall_acc, overall_acc_avg = get_acc(P_erm, models, testloader)\n",
    "\n",
    "1 - acc_tshirt_avg, 1 - acc_pull_avg, 1 - acc_shirt_avg, 1 - overall_acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
